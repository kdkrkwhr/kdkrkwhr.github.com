---
layout: post
author: Kim, DongKi
title:  "Spring Boot MSA ì ìš©ê¸°- 2íƒ„"
date:   2022-01-08
categories: Technology
comments: true
---

### TL;DR

ì•ˆë…•í•˜ì„¸ìš”, ë²Œì¨ 2022ë…„ ìƒˆí•´ë„¤ìš” ğŸ™†â€â™‚ï¸
ë‹¤ë“¤ ìƒˆí•´ ë³µ ë§ì´ ë°›ìœ¼ì„¸ìš” ğŸ™‡

ì´ë²ˆ í¬ìŠ¤íŒ…ì€ ì´ì „ê³¼ ì´ì–´ì„œ MSA ê´€ë ¨ í¬ìŠ¤íŒ…ì„ ì£¼ì œë¡œ ê°€ê² ìŠµë‹ˆë‹¤ ğŸ˜ƒ

----
### Zuul Filtering

- Zuul Gatewayë¥¼ í†µí•œ ìš”ì²­ ì²˜ë¦¬ ì‹œ ë¯¸ì¸ì¦ ìš”ì²­ í˜¹ì€ ê°ì¢… ì´ìŠˆ ìƒí™© ë°œìƒ ì‹œ ìš°ì„  ëŒ€ì‘ì„ ë„ì™€ì£¼ëŠ” ê¸°ëŠ¥

- Zuul Filter Type
  + Pre Filter
    - ì„œë¹„ìŠ¤ ì²˜ë¦¬ ì „ ì‹¤í–‰ë˜ëŠ” í•„í„° (Security, ì¸ì¦ ì²˜ë¦¬ ë“±)
  + Post Filter
    - ì„œë¹„ìŠ¤ ì²˜ë¦¬ ì´í›„ ì‹¤í–‰ë˜ëŠ” í•„í„° (API ì²˜ë¦¬ í†µê³„ ì²˜ë¦¬ ë“±)
  + Route Filter
    - ê° ì„œë¹„ìŠ¤ ì»´í¬ë„ŒíŠ¸ ë‚´ ë¼ìš°íŒ… ì œì–´ë¥¼ ìœ„í•œ í•„í„° (Ribbon, ë™ì  ë¼ìš°íŒ… ê´€ë¦¬)
  + Error Filter
    - í•„í„° ì˜ì—­ ë‚´ ë°œìƒë˜ëŠ” ì´ìŠˆ ìƒí™© ì²˜ë¦¬ ì‹¤í–‰ì„ ìœ„í•œ í•„í„°

#### Filter êµ¬í˜„

- ZuulFilterë¥¼ ìƒì†ë°›ëŠ” ê° í•„í„° ì²˜ë¦¬ ì»¤ìŠ¤í…€ í´ë˜ìŠ¤ë¥¼ êµ¬í˜„ 
  - ê° ì»¤ìŠ¤í…€ í•„í„° í´ë˜ìŠ¤ ë‚´ ì²˜ë¦¬ ë¡œì§ ì‘ì„±

[PreFilter.java]
```java
public class PreFilter extends ZuulFilter {

  private static final Logger logger = LoggerFactory.getLogger(PreFilter.class);

  @Override
  public String filterType() {
    return "pre";
  }

  @Override
  public int filterOrder() {
    return 0;
  }

  @Override
  public boolean shouldFilter() {
    return true;
  }

  @Override
  public Object run() {
    RequestContext requestContext = RequestContext.getCurrentContext();
    HttpServletRequest httpServletRequest = requestContext.getRequest();
    logger.info("===== ZUUL::PRE =====");
    logger.info("Request URL :: {} Request Method :: {}", 
        httpServletRequest.getRequestURI(),
        httpServletRequest.getMethod());

    return null;
  }
}
```

[PostFilter.java]
```java
public class PostFilter extends ZuulFilter {

  private static final Logger logger = LoggerFactory.getLogger(RouteFilter.class);

  @Override
  public String filterType() {
    return "post";
  }

  @Override
  public int filterOrder() {
    return 0;
  }

  @Override
  public boolean shouldFilter() {
    return true;
  }

  @Override
  public Object run() {
    logger.info("===== ZUUL::POST =====");
    return null;
  }
}
```

[RouteFilter.java]
```java
public class RouteFilter extends ZuulFilter {

  private static final Logger logger = LoggerFactory.getLogger(RouteFilter.class);

  @Override
  public String filterType() {
    return "route";
  }

  @Override
  public int filterOrder() {
    return 0;
  }

  @Override
  public boolean shouldFilter() {
    return true;
  }

  @Override
  public Object run() {
    logger.info("===== ZUUL::ROUTE =====");
    return null;
  }
}
```

[ErrorFilter.java]
```java
public class ErrorFilter extends ZuulFilter {

  private static final Logger logger = LoggerFactory.getLogger(RouteFilter.class);
  
  @Override
  public String filterType() {
    return "error";
  }

  @Override
  public int filterOrder() {
    return 0;
  }

  @Override
  public boolean shouldFilter() {
    return true;
  }

  @Override
  public Object run() {
    logger.error("===== ZUUL::ERROR =====");
    return null;
  }
}
```

- êµ¬í˜„ í•œ ì»¤ìŠ¤í…€ í´ë˜ìŠ¤ë¥¼ Bean íŒŒì¼ë¡œ ë“±ë¡

[DefaultServerApplication.java]

```java
@SpringBootApplication
@EnableZuulProxy
@EnableDiscoveryClient
public class DefaultServerApplication {

  public static void main(String[] args) {
    SpringApplication.run(DefaultServerApplication.class, args);
  }

  @Bean
  public PreFilter preFilter() {
    return new PreFilter();
  }

  @Bean
  public PostFilter postFilter() {
    return new PostFilter();
  }

  @Bean
  public ErrorFilter errorFilter() {
    return new ErrorFilter();
  }

  @Bean
  public RouteFilter routeFilter() {
    return new RouteFilter();
  }
}
```

#### Filter Test

![2022-01-08-msa-start-2-1.jpg](/assets/2022-01-08-msa-start-2-1.jpg)

![2022-01-08-msa-start-2-2.jpg](/assets/2022-01-08-msa-start-2-2.jpg)

- í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì§€ì •í•œ Filter í´ë˜ìŠ¤ë¥¼ ìˆ˜í–‰í•˜ëŠ”ê±¸ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.


ì¶”ê°€ë¡œ ì´ì „ í¬ìŠ¤íŒ…ì— ì ì—ˆë˜ ë°”ì™€ ê°™ì´ Python ê¸°ë°˜ ì»´í¬ë„ŒíŠ¸ë„ Eureka ì„œë¹„ìŠ¤ë¡œ ë¶™ì´ëŠ” ì˜ˆì‹œë¥¼ ë³´ì—¬ë“œë¦¬ê³  ì˜¤ëŠ˜ í¬ìŠ¤íŒ…ì€ ë§ˆë¬´ë¦¬ í•˜ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤ :)  


### Python Flask - Netflex Eureka

#### í•„ìš”í•œ Python Lib 
- flask
- flask_restx
- py_eureka_client

![2022-01-08-msa-start-2-3.jpg](/assets/2022-01-08-msa-start-2-3.jpg)

#### Python ì´ìš©í•œ Eureka ì»´í¬ë„ŒíŠ¸ êµ¬í˜„

ë¨¼ì € ê°„ë‹¨í•œ ì»´í¬ë„ŒíŠ¸ë¡œ êµ¬ì„±ì„ í•  ìƒê°ì´ê¸° ë•Œë¬¸ì— Flaskë¥¼ ì´ìš©í•œ í¬ë¡¤ë§ì„ êµ¬í˜„í•´ ë³´ê² ìŠµë‹ˆë‹¤.

- ì»´í¬ë„ŒíŠ¸ ë‚´ ë©”ì¸ì´ ë˜ëŠ” í´ë˜ìŠ¤ 

[app.py]

```python
from flask import Flask, request
from flask_restx import Api
from flask_cors import CORS
import py_eureka_client.eureka_client as eureka_client
import crawling
import config.server_config as server

app = Flask(__name__)
api = Api(app)
CORS(app)

eureka_client.init(eureka_server=server.EUREKA_SERVER,
                   app_name=server.SERVICE_NAME,
                   instance_host=server.SERVICE_HOST,
                   instance_port=server.SERVICE_PORT)

@app.route("/craw/url", methods=['GET'])
def get_crawling_url():
  return crawling.crawler('https://github.com/kdkrkwhr')

@app.route("/craw/get_data", methods=['POST'])
def post_crawling_data():
  params = request.get_json()
  return crawling.crawler_parsing(params['url'], params['tag'])

@app.route("/craw/test", methods=['GET'])
def test():
  args = request.args
  param = args['param']
  return {"message" : "Hi", "param" : param}

if __name__ == "__main__": 
  app.run(host=server.SERVICE_HOST, port=server.SERVICE_PORT, debug=True)
```

- Eureka ì„¤ì • íŒŒì¼

[server_config.py]
```python
SERVICE_NAME = 'kdk-eureka-zuul-service-flask'
SERVICE_PORT = 8102
SERVICE_HOST = '127.0.0.1'
EUREKA_SERVER = 'http://localhost:8081/eureka/'
```

- ì‹¤ì œ í¬ë¡¤ë§ ì„œë¹„ìŠ¤ ë¡œì§
  + í˜¸ì¶œí•œ Url htmlì„ ê°€ì ¸ì˜¤ë„ë¡ êµ¬í˜„
  + í˜¸ì¶œí•œ Url html ë‚´ íŠ¹ì • íƒœê·¸ ê°’ì„ ê°€ì ¸ì˜¤ë„ë¡ êµ¬í˜„


[crawling.py]
```python
import requests
from bs4 import BeautifulSoup

def crawler(url):
  html = requests.get(url)
  return html.text

def crawler_parsing(url, tag):
  html = requests.get(url)
  soup = BeautifulSoup(html.text, 'html.parser')
  select = soup.select_one(tag)

  return select.text
```

#### Test

- ì •ìƒì ìœ¼ë¡œ Discovery ëœ ê²ƒì„ í™•ì¸

![2022-01-08-msa-start-2-4.jpg](/assets/2022-01-08-msa-start-2-4.jpg)

- ì •ìƒì ìœ¼ë¡œ Zuulì„ ì´ìš©í•œ Routingì´ ì™„ìˆ˜ ëœ ê²ƒì„ í™•ì¸

![2022-01-08-msa-start-2-5.jpg](/assets/2022-01-08-msa-start-2-5.jpg)


### ë§ˆë¬´ë¦¬

MSAëŠ” ê³„ì† í¥ë¯¸ë¥¼ ê°€ì§€ê³  ìˆëŠ” ì£¼ì œë¡œ ì•„ì§ê¹Œì§€ë„ í‹ˆí‹ˆíˆ ê³µë¶€ë¥¼ í•˜ê³  ìˆìŠµë‹ˆë‹¤. 

ê·¸ë˜ì„œ ì•ìœ¼ë¡œë„ ê´€ë ¨ëœ í¬ìŠ¤íŒ…ì„ ì‘ì„±í•  ìˆ˜ê°€ ìˆì„ ê²ƒ ê°™ìŠµë‹ˆë‹¤ ğŸ˜Š

ë‹¤ì‹œ í•œ ë²ˆ ìƒˆí•´ ë³µ ë§ì´ ë°›ìœ¼ì‹œê³ , í¸ì•ˆí•œ í•œ í•´ ë˜ê¸¸ ë°”ëë‹ˆë‹¤ ~

Thanks .